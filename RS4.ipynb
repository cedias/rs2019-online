{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Recommenders 4 : Pytorch and Recommenders (~1h)\n", "\n", "In this practical session, we dive a little more into [pytorch](https://pytorch.org/docs/stable/index.html) and propose to re-implement two classical matrix-factorization models with this neural network toolkit.\n", "\n", "## Objectives:\n", "\n", "- (a) See a bit of simple pytorch (~5min)\n", "- (b) Discover the \"autograd\" part of pytorch to build a simple baseline (~20min)\n", "- (c) Discover the \"nn\" part of pytorch to build a simple matrix factorization algorithm (~20min)\n", "- (d) Learn to use a high level framework for pytorch (kind of \"KERAS\" like) to build more complicated algorithms (~15min)\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["import torch\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# (a) WHAT IS PYTORCH?\n", "\n", "It\u2019s a Python-based scientific computing package targeted at two sets of audiences:\n", "\n", "- A replacement for NumPy to use the power of GPUs\n", "- a deep learning research platform that provides maximum flexibility and speed\n", "\n", "### Tensors : the main unit\n", "\n", "Tensors are similar to NumPy\u2019s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n", "\n", "\n", "## Some useful functions:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Creating tensors"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### initialize an empty 4x2 matrix"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["tensor([[ 6.9440e-22,  4.5644e-41],\n", "        [ 6.9441e-22,  4.5644e-41],\n", "        [-9.6718e-14,  4.5644e-41],\n", "        [ 6.9398e-22,  4.5644e-41]])\n"]}], "source": ["x_empty = torch.empty(4, 2)\n", "print(x_empty)  #Tensor is not initialized => contains gibberish"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### create a 3x2 tensor filled with zeros of type long"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["tensor([[0, 0],\n", "        [0, 0],\n", "        [0, 0]])\n"]}], "source": ["x0 = torch.zeros(3, 2, dtype=torch.long)\n", "print(x0) #Tensor has only zeros"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### create a tensor of size 2 with (0 => 5.5) and (1 => 3)"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["tensor([5.5000, 3.0000])\n"]}], "source": ["x_data = torch.tensor([5.5, 3])\n", "print(x_data) "]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["tensor([5.5000, 3.0000], dtype=torch.float64)\n"]}], "source": ["x_data = torch.tensor(np.array([5.5, 3])) #also works with numpy arrays\n", "print(x_data) "]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### create random 5x3 and 3x5 tensors "]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["tensor([[0.2676, 0.0118, 0.5148],\n", "        [0.2574, 0.5060, 0.2532],\n", "        [0.9016, 0.1810, 0.7213],\n", "        [0.3462, 0.8824, 0.9259],\n", "        [0.8866, 0.6959, 0.2074]])\n"]}], "source": ["x = torch.rand(5,3)\n", "y = torch.rand(3,5)\n", "print(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Indexing works just like numpy "]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/plain": ["tensor([0.0118, 0.5060, 0.1810, 0.8824, 0.6959])"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["x[:,1] #The 2nd column (indexing starts at 0)"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"data": {"text/plain": ["tensor([[0.2574, 0.5060, 0.2532],\n", "        [0.3462, 0.8824, 0.9259]])"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["x[[1,3],:] # the 2nd and 4th row "]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["1\n"]}], "source": ["scalar = torch.tensor([1])\n", "print(scalar.item()) # Gets the value when tensor is a scalar"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### know the size of a tensor"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"data": {"text/plain": ["torch.Size([5, 3])"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["x.size() ## equivalent to x.shape in numpy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### simple addition"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/plain": ["tensor([[1.2676, 1.0118, 1.5148],\n", "        [1.2574, 1.5060, 1.2532],\n", "        [1.9016, 1.1810, 1.7213],\n", "        [1.3462, 1.8824, 1.9259],\n", "        [1.8866, 1.6959, 1.2074]])"]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["x+1        # same as x.add(1)\n", "x.add_(1)  # inplace"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### matrix multiplication"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"data": {"text/plain": ["tensor([[1.6695, 2.1861, 2.5253, 1.6731, 2.1123],\n", "        [1.9295, 1.9528, 2.8488, 1.8503, 2.1958],\n", "        [1.9377, 2.8006, 3.3204, 1.9618, 2.7357],\n", "        [2.5962, 2.5981, 3.4723, 2.5037, 2.7704],\n", "        [2.0797, 2.3450, 3.5737, 2.0049, 2.6969]])"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["torch.mm(x,y) # same as x @ y or np.dot(x.numpy(),y.numpy())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### What to understand:\n", "\n", "Pytorch can be a drop-in replacement for numpy. It behaves mostly the same and the API is close.\n", "\n", "\n", "### There are many more creation/operation ops:\n", "\n", "=> You can have a look at the [torch.Tensor documentation](https://pytorch.org/docs/stable/tensors.html)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## What's interesting beyond the \"numpy replacement\": autodiff !\n", "\n", "Pytorch has Automatic differentiation: You only have to compute a loss function to obtain gradients automatically. How it works is detailed [here](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-tensors-and-autograd)\n", "\n", "### Let's do 1d-linear regression with the vanilla autodiff !\n", "\n", "#### (First) we need fake data:"]}, {"cell_type": "code", "execution_count": 38, "metadata": {}, "outputs": [{"data": {"text/plain": ["[<matplotlib.lines.Line2D at 0x7f3d1a94d198>]"]}, "execution_count": 38, "metadata": {}, "output_type": "execute_result"}, {"data": {"image/png": "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\n", "text/plain": ["<Figure size 432x288 with 1 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}], "source": ["fake_x = np.arange(0,100,1)\n", "fake_y = np.arange(0,10,0.1) + np.random.rand(100)\n", "plt.plot(fake_x,fake_y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**NOTE:** Here, we won't split the data in train/val/test, this is just an example\n", "\n", "So, the linear model we want to learn is the following:\n", "$$f(x) =  wx+b $$\n", "The parameters to optimize are w and b."]}, {"cell_type": "code", "execution_count": 166, "metadata": {}, "outputs": [], "source": ["# First we create to tensor variables (which are our parameters)\n", "w = torch.tensor([1.],requires_grad=True) # We need to set requires_grad to True so the gradient can flow.\n", "b = torch.tensor([0.5],requires_grad=True)"]}, {"cell_type": "code", "execution_count": 167, "metadata": {}, "outputs": [], "source": ["# We define the f function:\n", "def f(x):\n", "    return (w*x)+b"]}, {"cell_type": "code", "execution_count": 176, "metadata": {}, "outputs": [], "source": ["# We define an error function (here the MAE)\n", "def error(pred,real):\n", "    return (pred-real).abs()"]}, {"cell_type": "code", "execution_count": 191, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["----\n", "loss: 0.3711300665140152\n", "w: 0.10132084786891937\n", "b: 0.46678513288497925\n", "----\n", "loss: 0.3334507894515991\n", "w: 0.11272084712982178\n", "b: 0.46678513288497925\n", "----\n", "loss: 0.37345377743244174\n", "w: 0.09972088038921356\n", "b: 0.46618521213531494\n", "----\n", "loss: 0.37115800857543946\n", "w: 0.10112091898918152\n", "b: 0.46618521213531494\n"]}, {"data": {"text/plain": ["<matplotlib.legend.Legend at 0x7f3d14e5c7b8>"]}, "execution_count": 191, "metadata": {}, "output_type": "execute_result"}, {"data": {"image/png": "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\n", "text/plain": ["<Figure size 432x288 with 1 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}], "source": ["# Finally, we cycle through the data, optimizing the parameters with respect to the gradient of the error:\n", "plt.plot(fake_y)\n", "\n", "for epoch in range(4): # We cycle 4 times\n", "    mean_loss = 0\n", "    \n", "    for x,y in zip(fake_x,fake_y): \n", "        \n", "        pred = f(x) #predict\n", "        loss = error(pred,y) #compute loss\n", "        loss.backward() # This does backpropagation and sets .grad attribute.\n", "\n", "        # Update parameters via SGD:\n", "        with torch.no_grad(): # This deactivated gradient calculations\n", "            \n", "            mean_loss += loss.item() # get the raw value of a (1,) tensor\n", "            w -= 0.0001 * w.grad # This wouldn't be possible w/ gradient (-= is an inplace operation)\n", "            b -= 0.0001 * b.grad\n", "            w.grad.zero_()\n", "            b.grad.zero_()\n", "            \n", "    # Plot the resulting line        \n", "    predictions = [f(x) for x in range(100)]\n", "    plt.plot(predictions,label=f\"epoch {epoch}\")\n", "\n", "    print('----')\n", "    print(\"loss:\", mean_loss/len(fake_y))\n", "    print('w:',w.item())\n", "    print('b:',b.item())\n", "    \n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "# Full pytorch tutorial: \n", "\n", "A tutorial can be found [here](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) do not hesitate to take a couple of minutes to skim read it. Plenty of [ressources](https://pytorch.org/resources) are available online. Also, you can have a look at the [extensive pytorch documentation](https://pytorch.org/docs/stable/index.html). \n", "\n", "Here, as we are defining neural networks, we mainly use the `torch.nn` module which contains most classical deep learning building blocks\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data used : [smallest movie-lens dataset](https://grouplens.org/datasets/movielens/)\n", "\n", "=> Just like the previous sessions\n", "\n", "\n", "# 1)  Load & Prepare Data\n", "\n", "To be able to embed the data easily, we need to remap  the user/items between [0->N_User] and [0->N_Items]."]}, {"cell_type": "code", "execution_count": 192, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": [" #train:64535, #val:16133 ,#test:20168\n"]}], "source": ["from random import shuffle\n", "\n", "## Load\n", "ratings = pd.read_csv(\"https://raw.githubusercontent.com/cedias/csvdata/master/ratings.csv\")\n", "ratings.head(5)\n", "\n", "## Prepare Data\n", "user_map = {user:num for num,user in enumerate(ratings[\"userId\"].unique())}\n", "item_map = {item:num for num,item in enumerate(ratings[\"movieId\"].unique())}\n", "\n", "## Number of users & items\n", "num_users = len(user_map)\n", "num_items = len(item_map)\n", "\n", "ratings[\"userId\"] = ratings[\"userId\"].map(user_map)\n", "ratings[\"movieId\"] = ratings[\"movieId\"].map(item_map)\n", "\n", "ratings.head(5)\n", "\n", "# Creating Test/Train as before\n", "\n", "train_indexes,val_indexes,test_indexes = [],[],[]\n", "\n", "for index in range(len(ratings)):\n", "    if index%5 == 0:\n", "        test_indexes.append(index)\n", "    else:\n", "        train_indexes.append(index)\n", "\n", "        \n", "shuffle(train_indexes)\n", "num_val = int(len(train_indexes)/100*20)\n", "val_indexes = train_indexes[:num_val]\n", "train_indexes = train_indexes[num_val:]\n", "\n", "train_ratings = ratings.iloc[train_indexes].copy()\n", "val_ratings = ratings.iloc[val_indexes].copy()\n", "test_ratings = ratings.iloc[test_indexes].copy()\n", "\n", "\n", "print(f\" #train:{len(train_ratings)}, #val:{len(val_ratings)} ,#test:{len(test_ratings)}\" )\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## (TODO) Reproduce the baseline model with pytorch's vanilla autograd"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Your goal now is to reproduce the following baseline model from surprise\n", "\n", "## $$\\hat{r}_{ui} = b_{ui} = \\mu + b_u + b_i$$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## (TODO) : First, let's define the parameters\n", "\n", "You have many parameters, they are all 1-dimensional:\n", "- **mu:** the global mean (1,)\n", "- **bu:** the user means (n_users,)\n", "- **bi:** the item means (n_items,)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mu = #To Complete\n", "bu = [ #To Complete for _ in range(num_users)]    --- use a list of torch.tensor() not one torch tensor\n", "bi = [ #To Complete for _ in range(num_items)]    --- use a list of torch.tensor() not one torch tensor"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "Then, we define two functions: \n", "\n", "- `predict(u,i)` : Will return the prediction given the (user,item) pair\n", "- `error(pred,real)` : Will return the MSE error of prediction"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### (TODO) Predict Function\n", "This function should implement this: $\\hat{r}_{ui} = b_{ui} = \\mu + b_u + b_i$"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def predict(u,i):\n", "    \n", "    if u < num_users: # if user exist:\n", "        user_mean = #To Complete\n", "    else:\n", "        user_mean = #To Complete\n", "        \n", "    if i < num_items: # if item exist:\n", "        item_mean = #To Complete\n", "    else:\n", "        item_mean = #To Complete\n", "        \n", "    return #To Complete"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### (TODO) error function\n", "We want to use the MSE"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def error(pred,real):\n", "    return #To Complete"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### The evaluation loop, without any optimization for now"]}, {"cell_type": "code", "execution_count": 144, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["final train error :  1.1252629729070505\n", "final val error :  1.1421198134811563\n", "final test error :  1.1166436290324107\n"]}], "source": ["train_e = 0\n", "for index, uid, mid, r, ts in train_ratings.itertuples():\n", "    result = predict(uid,mid)\n", "    train_e += error(result,r).item()\n", "    \n", "val_e = 0\n", "for index, uid, mid, r, ts in val_ratings.itertuples():\n", "    result = predict(uid,mid)\n", "    val_e += error(result,r).item()\n", "\n", "test_e = 0\n", "for index, uid, mid, r, ts in test_ratings.itertuples():\n", "    result = predict(uid,mid)\n", "    test_e += error(result,r).item()\n", "\n", "print(\"final train error : \", train_e/len(train_ratings))\n", "print(\"final val error : \", val_e/len(val_ratings))\n", "print(\"final test error : \", test_e/len(test_ratings))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Let's optimize the parameters (with SGD)  by slightly modifying the previous loop\n", "\n", "### (TODO)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lr = 0.01\n", "batch_size = 32\n", "n_epochs = 5\n", "\n", "for epoch in range(n_epochs):\n", "    \n", "    train_error = 0\n", "    \n", "    for num,(index, uid, mid, r, ts) in enumerate(train_ratings.sample(frac=1).itertuples()):\n", "        result = #To Complete\n", "        ex_error = #To Complete\n", "        train_error += #To Complete\n", "        \n", "        ex_error.backward()\n", "\n", "        if num % batch_size == 0:\n", "            \n", "            with torch.no_grad():\n", "                mu -= #To Complete\n", "                bu[uid] -= #To Complete\n", "                bi[mid] -= #To Complete\n", "\n", "                # Manually zero the gradients after updating weights\n", "                mu.grad.zero_()\n", "                bu[uid].grad.zero_()\n", "                bi[mid].grad.zero_()\n", "\n", "\n", "    print(f\"epoch {epoch} train error : \", train_e/len(train_ratings))\n", "    \n", "    val_e = 0\n", "    for index, uid, mid, r, ts in val_ratings.itertuples():\n", "        result = predict(uid,mid)\n", "        val_e += error(result,r).item()\n", "\n", "    print(f\"epoch {epoch} val error : \", val_e/len(val_ratings))\n", "\n", "\n", "    test_e = 0\n", "    for index, uid, mid, r, ts in test_ratings.itertuples():\n", "        result = predict(uid,mid)\n", "        test_e += error(result,r).item()\n", "\n", "    print(f\"epoch {epoch} test error : \", test_e/len(test_ratings))\n", "    print(\"-----\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#  Pytorch (.nn) Modules\n", "\n", "Instead of having to define everything by hand, pytorch has several usefull abstractions:\n", "\n", "- `nn.Module()` -> To define the model and the forward computation\n", "- `torch.utils.data.DataLoader` -> To create the data pipeline\n", "\n", "To explore these modules, we'll do the following model:\n", "\n", "##  Classic SVD (with mean)\n", "\n", "To see how it works, we propose to implement a simple SVD:\n", "### $$ \\min\\limits_{U,I}\\sum\\limits_{(u,i)} \\underbrace{(r_{ui} -  (I_i^TU_u + \\mu))^2}_\\text{minimization} + \\underbrace{\\lambda(||U_u||^2+||I_u||^2 + \\mu) }_\\text{regularization} $$\n", "\n", "where prediction is done in the following way:\n", "###\u00a0$$r_{ui} = \\mu + U_u.I_i $$\n", "\n", "where $\\mu$ is the global mean,  $U_u$ a user embedding and $I_i$ an item embedding\n", "\n", "### STEPS:\n", " To implement such model in pytorch, we need to do multiple things:\n", " \n", " - (1) model definition\n", " - (2) loss function\n", " - (3) evaluation\n", " - (4) training/eval loop\n", "\n", "\n", "#### (1) Model definition\n", "\n", "A model class typically extends `nn.Module`, the Neural network module. It is a convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.\n", "\n", "One should define two functions: `__init__` and `forward`.\n", "\n", "- `__init__` is used to initialize the model parameters\n", "- `forward` is the net transformation from input to output. In fact, when doing `moduleClass(input)` you call this method.\n", "\n", "##### (a) Initialization\n", "\n", "Our model has different weigths:\n", "\n", "- the user profiles (also called user embeddings) $U$\n", "- the item profiles (also called user embeddings) $I$\n", "- the mean bias $\\mu$\n", "\n", "\n", "##### (b) input to output operation\n", "Technically, the prediction as defined earlier can be seen as just a dot product between two embeddings $U_u$ and $I_i$ plus the mean rating:\n", "\n", "- `torch.sum(embed_u*embed_i,1) + self.mean` is equivalent to $r_{ui} = \\mu + U_u.I_i $ \n", "- the `.squeeze(1)` operation is a shape operation to remove the dimension 1 (indexing starts at 0) akin to reshaping the matrix from `(batch_size,1,latent_size)` to `(batch_size,latent_size)`\n", "- for reference, the inverse operation is `.unsqueeze()`\n", "- we return weights to regularize them\n", "\n", "\n", "### (TODO) Just to make sure you were following: complete the following `forward` method"]}, {"cell_type": "code", "execution_count": 195, "metadata": {}, "outputs": [], "source": ["#  Let's create the datasets following  (Object w/ __getitem__(index) and __len()__, i.e lists ;)\n", "prep_train = [(tp.userId,tp.movieId,tp.rating) for tp in train_ratings.itertuples()]\n", "prep_val = [(tp.userId,tp.movieId,tp.rating) for tp in val_ratings.itertuples()]\n", "prep_test = [(tp.userId,tp.movieId,tp.rating) for tp in test_ratings.itertuples()]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "\n", "\n", "# The model define as a class, inheriting from nn.Module\n", "class ClassicMF(nn.Module):\n", "    \n", "    #(a) Init\n", "    def __init__(self,nb_users,nb_items,latent_size):\n", "        super(ClassicMF, self).__init__()\n", "        \n", "        #Embedding layers\n", "        self.users = nn.Embedding(#To Complete, latent_size)        \n", "        self.items = nn.Embedding(#To Complete, latent_size)\n", "        #The mean bias\n", "        self.mean = nn.Parameter(torch.FloatTensor(1,).fill_(3))\n", "        \n", "        #initialize weights with very small values\n", "        nn.init.normal_(self.users.weight,0,0.01)\n", "        nn.init.normal_(self.items.weight,0,0.01)\n", "\n", "    \n", "    # (b) How we compute the prediction (from input to output)\n", "    def forward(self, user, item): ## method called when doing ClassicMF(user,item)\n", "        \n", "        embed_u,embed_i = self.users(user).squeeze(1),self.items(item).squeeze(1)\n", "        out =  #To Complete\n", "\n", "        return out, embed_u, embed_i, self.mean  # We return prediction + weights to regularize them\n", "    \n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### (2-4) full train loop\n", "\n", "The train loop is organized around the [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) class which Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset.\n", "\n", "We just redefine a collate function\n", "\n", "> collate_fn (callable, optional) \u2013 merges a list of samples to form a mini-batch.\n", "\n", "\n", "**NOTE:** The dataset argument can be a list instead of a \"Dataset\" instance (works by duck typing)\n", "    \n", "\n", "##### The train loop sequence is the following:\n", "    \n", "[Dataset ==Dataloader==> Batch (not prepared) ==collate_fn==> Batch (prepared) ==Model.forward==> Prediction =loss_fn=> loss <-> truth \n", "\n", "1] PREDICT\n", "- (a) The dataloader samples training exemples from the dataset (which is a list)\n", "- (b) The collate_fn prepares the minibatch of training exemples\n", "- (c) The prediction is made by feeding the minibatch in the model\n", "- (d) The loss is computed on the prediction via a loss function\n", "\n", "2] OPTIMIZE\n", "- (e) Gradients are computed by automatic backard propagation\n", "- (f) Parameters are updated using computed gradients"]}, {"cell_type": "code", "execution_count": 200, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["-------------------------\n", "epoch 0 mse (train/val/test) 1.037 / 0.924 / 0.892\n", "-------------------------\n", "epoch 1 mse (train/val/test) 0.776 / 0.83 / 0.793\n", "-------------------------\n", "epoch 2 mse (train/val/test) 0.604 / 0.809 / 0.772\n"]}], "source": ["from torch.utils.data import DataLoader\n", "import torch.nn.functional as F\n", "\n", "\n", "# HyperParameters\n", "n_epochs = 3\n", "batch_size = 16\n", "num_feat = 25\n", "lr = 0.01\n", "reg = 0.001\n", "\n", "\n", "#(b) Collate function => Creates tensor batches to feed model during training\n", "# It can be removed if data is already tensors (torch or numpy ;)\n", "def tuple_batch(l):\n", "    '''\n", "    input l: list of (user,item,rating tuples)\n", "    output: formatted batches (in torch tensors)\n", "\n", "    takes n-tuples and create batch\n", "    text -> seq word #id\n", "    '''\n", "    users, items, ratings = zip(*l) \n", "    users_t = torch.LongTensor(users)\n", "    items_t = torch.LongTensor(items)\n", "    ratings_t = torch.FloatTensor(ratings)\n", "    \n", "    return users_t, items_t, ratings_t\n", "    \n", "\n", "\n", "#(d) Loss function => Combines MSE and L2\n", "def loss_func(pred,ratings_t,reg,*params):\n", "    '''\n", "    mse loss combined with l2 regularization.\n", "    params assumed 2-dimension\n", "    '''\n", "    mse = F.mse_loss(pred,ratings_t,reduction='sum')\n", "    l2 = 0\n", "    for p in params:\n", "        l2 += torch.mean(p.norm(2,-1))\n", "        \n", "    return (mse/pred.size(0)) + reg*l2 , mse\n", "    \n", "#\n", "# Training script starts here\n", "#    \n", "\n", "\n", "model = ClassicMF(num_users,num_items,num_feat)\n", "\n", "\n", "\n", "# (a) dataloader will sample data from datasets using collate_fn tuple_batch\n", "dataloader_train = DataLoader(prep_train, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=tuple_batch)\n", "dataloader_val = DataLoader(prep_val, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=tuple_batch)\n", "dataloader_test = DataLoader(prep_test, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=tuple_batch)\n", "\n", "optimizer = torch.optim.Adam(model.parameters())\n", "\n", "# Train loop\n", "for e in range(n_epochs):\n", "    mean_loss = [0,0,0] #train/val/test\n", "\n", "    ## Training loss (the one we train with)\n", "    \n", "    for users_t,items_t,ratings_t in dataloader_train:\n", "        model.train() # set the model on train mode\n", "        model.zero_grad() # reset gradients\n", "        \n", "        #(c) predictions are made by the model\n", "        pred,*params = model(users_t,items_t)\n", "        \n", "        #(d) loss computed on predictions, we added regularization\n", "        loss,mse_loss = loss_func(pred,ratings_t,reg,*params)\n", "        \n", "        loss.backward() #(e) backpropagating to get gradients\n", "        \n", "        mean_loss[0] += mse_loss\n", "        optimizer.step() #(f) updating parameters\n", "    \n", "    with torch.no_grad():\n", "        ## Validation loss (no training)\n", "        for users_t,items_t,ratings_t in dataloader_val:\n", "\n", "            model.eval() # Inference mode\n", "            pred,*params = model(users_t,items_t)\n", "            _,mse_loss = loss_func(pred,ratings_t,reg,*params)\n", "\n", "            mean_loss[1] += mse_loss    \n", "\n", "        ## Test loss (no training)\n", "\n", "        for users_t,items_t,ratings_t in dataloader_test:\n", "            model.eval()\n", "            pred,*params = model(users_t,items_t)\n", "            _,mse_loss = loss_func(pred,ratings_t,reg,*params)\n", "\n", "            mean_loss[2] += mse_loss    \n", "\n", "    print(\"-\"*25)\n", "    print(\"epoch\",e, \"mse (train/val/test)\", round((mean_loss[0]/len(prep_train)).item(),3),\"/\",  round((mean_loss[1]/len(prep_val)).item(),3),\"/\",  round((mean_loss[2]/len(prep_test)).item(),3))\n", "    \n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## (Your turn) Koren 2009 model:\n", "\n", "Here, this model simply adds a bias for each user and for each item\n", "\n", "### $$ \\min\\limits_{U,I}\\sum\\limits_{(u,i)} \\underbrace{(r_{ui} -  (I_i^TU_u + \\mu+ \\mu_i+\\mu_u))^2}_\\text{minimization} + \\underbrace{\\lambda(||U_u||^2+||I_u||^2 + \\mu  + \\mu+ \\mu_i+\\mu_u) }_\\text{regularization} $$\n", "\n", "\n", "### $$r_{ui} = \\mu + \\mu_i + \\mu_u + U_u.I_i $$\n", "\n", "### TODO:\n", "\n", "- (a) complete the model initialization\n", "- (b) complete the forward method"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class KorenMF(nn.Module):\n", "\n", "    def __init__(self,nb_users,nb_items,latent_size):\n", "        super(KorenMF, self).__init__()\n", "        \n", "        self.users = #To Complete\n", "        self.items = #To Complete\n", "        self.umean = #To Complete\n", "        self.imean = #To Complete\n", "        self.gmean =  #To Complete\n", "\n", "        nn.init.normal_(self.users.weight,0,0.01)\n", "        nn.init.normal_(self.items.weight,0,0.01)\n", "        nn.init.normal_(self.umean.weight,2,1)\n", "        nn.init.normal_(self.imean.weight,2,1)\n", "        \n", "        \n", "    def forward(self, user,item):\n", "        embed_u,embed_i = self.users(user).squeeze(1) , self.items(item).squeeze(1)\n", "        umean, imean = self.umean(user) , self.imean(item)\n", "        out = #To Complete\n", "\n", "        return out , embed_u, embed_i, umean , imean , self.gmean"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### (TODO) Here, train loop stays the same, you only have to change the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from torch.utils.data import DataLoader\n", "import torch.nn.functional as F\n", "\n", "n_epochs = 10\n", "batch_size = 16\n", "num_feat = 25\n", "lr = 0.01\n", "reg = 0.001\n", "\n", "\n", "\n", "def tuple_batch(l):\n", "    '''\n", "    input l: list of (user,item,review, rating tuples)\n", "    output: formatted batches (in torch tensors)\n", "\n", "    takes n-tuples and create batch\n", "    text -> seq word #id\n", "    '''\n", "    users, items,ratings = zip(*l)\n", "    users_t = torch.LongTensor(users)\n", "    items_t = torch.LongTensor(items)\n", "    ratings_t = torch.FloatTensor(ratings)\n", "    \n", "    return users_t,items_t,ratings_t\n", "\n", "\n", "def loss_func(pred,ratings_t,reg,*params):\n", "    '''\n", "    mse loss combined with l2 regularization.\n", "    params assumed 2-dimension\n", "    '''\n", "    mse = F.mse_loss(pred,ratings_t,reduction=\"sum\")\n", "    l2 = 0\n", "    for p in params:\n", "        l2 += torch.mean(p.norm(2,-1))\n", "        \n", "    return (mse/pred.size(0)) + reg*l2 , mse\n", "    \n", "\n", "model =  #To Complete\n", "\n", "\n", "dataloader_train = DataLoader(prep_train, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=tuple_batch)\n", "dataloader_val = DataLoader(prep_val, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=tuple_batch)\n", "dataloader_test = DataLoader(prep_test, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=tuple_batch)\n", "\n", "optimizer = torch.optim.Adam(model.parameters())\n", "\n", "\n", "for e in range(n_epochs):\n", "    mean_loss = [0,0,0] #train/val/test\n", "\n", "    for users_t,items_t,ratings_t in dataloader_train:\n", "        model.train()\n", "        model.zero_grad()\n", "        pred,*params = model(users_t,items_t)\n", "\n", "        loss,mse_loss = loss_func(pred,ratings_t,reg,*params)\n", "        loss.backward()\n", "        \n", "        mean_loss[0] += mse_loss\n", "        optimizer.step()\n", "    \n", "    \n", "\n", "    for users_t,items_t,ratings_t in dataloader_val:\n", "        model.eval()\n", "        pred,*params = model(users_t,items_t)\n", "        _,mse_loss = loss_func(pred,ratings_t,reg,*params)\n", "    \n", "        mean_loss[1] += mse_loss    \n", "        \n", "    for users_t,items_t,ratings_t in dataloader_test:\n", "        model.eval()\n", "        pred,*params = model(users_t,items_t)\n", "        _,mse_loss = loss_func(pred,ratings_t,reg,*params)\n", "    \n", "        mean_loss[2] += mse_loss    \n", "\n", "    print(\"-\"*25)\n", "    print(\"epoch\",e, \"mse (train/val/test)\", round((mean_loss[0]/len(prep_train)).item(),3),\"/\",  round((mean_loss[1]/len(prep_val)).item(),3),\"/\",  round((mean_loss[2]/len(prep_test)).item(),3))\n", "    \n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Pytorch's keras: Pytorch-Lightning\n", "\n", "Pytorch lightning is a easy to use framework for Pytorch. To start a new project you just need to define two files:\n", "\n", "- a LightningModule (which inherits `pl.LightningModule`)\n", "- a Trainer file. \n", "\n", "By defining those two files, you get:\n", "- Checkpointing\n", "- Debugging\n", "- Distributed training\n", "- Experiment Logging\n", "- Training loop\n", "- Validation loop\n", "- Testing loop\n", "\n", "## Let's try with the same but different Koren 2009 model:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "### $$r_{ui} = \\mu + \\mu_i + \\mu_u + U_u.I_i $$\n", "\n", "Where the goal is to minimize the following loss\n", "\n", "### $$ \\min\\limits_{U,I}\\sum\\limits_{(u,i)} \\underbrace{(r_{ui} -  (I_i^TU_u + \\mu+ \\mu_i+\\mu_u))^2}_\\text{minimization} + \\underbrace{\\lambda(||U_u||^2+||I_u||^2 + \\mu  + \\mu+ \\mu_i+\\mu_u) }_\\text{regularization} $$\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## (TODO) Complete the code"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "from torch.utils.data import DataLoader\n", "import torch.nn.functional as F\n", "import torch.nn as nn\n", "import pytorch_lightning as pl\n", "\n", "class LightningKorenMF(pl.LightningModule):\n", "\n", "    def __init__(self,nb_users,nb_items,latent_size):\n", "        super(LightningKorenMF, self).__init__()\n", "        \n", "        self.reg = 0.001\n", "        \n", "        self.users = #To Complete\n", "        self.items = #To Complete\n", "        self.umean = #To Complete\n", "        self.imean = #To Complete\n", "        self.gmean =  nn.Parameter(torch.FloatTensor(1,).fill_(3))\n", "\n", "        nn.init.normal_(self.users.weight,0,0.01)\n", "        nn.init.normal_(self.items.weight,0,0.01)\n", "        nn.init.normal_(self.umean.weight,0.1,0.1)\n", "        nn.init.normal_(self.imean.weight,0.1,0.1)\n", "        \n", "\n", "    def forward(self, user,item):\n", "        embed_u,embed_i = self.users(user).squeeze(1) , self.items(item).squeeze(1)\n", "        umean, imean = self.umean(user) , self.imean(item)\n", "        out = #To Complete\n", "\n", "        return out , embed_u, embed_i, umean , imean , self.gmean\n", "\n", "    \n", "    def my_loss_func(self, pred,ratings_t,reg,*params):\n", "        '''\n", "        mse loss combined with l2 regularization.\n", "        params assumed 2-dimension\n", "        '''        \n", "        mse = F.mse_loss(pred,ratings_t)\n", "        l2 = 0\n", "        for p in params:\n", "            l2 += torch.mean(p.norm(2,-1))\n", "\n", "        return mse + reg*l2 , mse\n", "    \n", "    def training_step(self, batch, batch_nb):\n", "        # REQUIRE\n", "        users_t,items_t,ratings_t = batch\n", "        pred , *params = self.forward(users_t,items_t) \n", "        loss,mse = self.my_loss_func(pred,ratings_t,self.reg,*params)\n", "\n", "        return {'loss':loss,\"mse\":mse}\n", "    \n", "\n", "    \n", "    def validation_step(self, batch, batch_nb):\n", "        return {\"val_mse\":self.training_step(batch,batch_nb)[\"mse\"]}\n", "    \n", "    def validation_end(self,outputs):\n", "        return {\"progress_bar\":{\"val_mse\":torch.tensor([output['val_mse'] for output in outputs]).mean().item()}}\n", "    \n", "    def test_step(self, batch, batch_nb):\n", "        return {\"test_mse\":self.training_step(batch,batch_nb)[\"mse\"]}\n", "    \n", "    def test_end(self,outputs):\n", "        res = {\"progress_bar\":{\"test_mse\":torch.tensor([output['test_mse'] for output in outputs]).mean().item()}}\n", "        print(res)\n", "        return res\n", "\n", "    \n", "    def configure_optimizers(self):\n", "        # REQUIRED\n", "        return torch.optim.Adam(self.parameters(), lr=0.002)\n", "    \n", "    def tuple_batch(self,l):\n", "        '''\n", "        input l: list of (user,item,rating tuples)\n", "        output: formatted batches (in torch tensors)\n", "\n", "        takes n-tuples and create batch\n", "        text -> seq word #id\n", "        '''\n", "        users, items, ratings = zip(*l) \n", "        users_t = torch.LongTensor(users)\n", "        items_t = torch.LongTensor(items)\n", "        ratings_t = torch.FloatTensor(ratings)\n", "\n", "        return users_t, items_t, ratings_t\n", "    \n", "\n", "    @pl.data_loader\n", "    def train_dataloader(self):\n", "        # REQUIRED\n", "        return DataLoader(prep_train,collate_fn=self.tuple_batch ,num_workers=0, batch_size=32)\n", "\n", "    @pl.data_loader\n", "    def val_dataloader(self):\n", "        # OPTIONAL\n", "        return DataLoader(prep_val,collate_fn=self.tuple_batch,num_workers=0, batch_size=32)\n", "\n", "    @pl.data_loader\n", "    def test_dataloader(self):\n", "        # OPTIONAL\n", "        return DataLoader(prep_test,collate_fn=self.tuple_batch,num_workers=0, batch_size=32)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train the model"]}, {"cell_type": "code", "execution_count": 206, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["INFO:root:    Name       Type Params\n", "0  users  Embedding   30 K\n", "1  items  Embedding  486 K\n", "2  umean  Embedding  610  \n", "3  imean  Embedding    9 K\n", "Epoch 1:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 2017/2522 [00:12<00:03, 163.60batch/s, batch_nb=2016, loss=0.787, v_nb=45]\n", "Epoch 1:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 2078/2522 [00:12<00:02, 212.92batch/s, batch_nb=2016, loss=0.787, v_nb=45]\n", "Epoch 1:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 2281/2522 [00:12<00:00, 291.04batch/s, batch_nb=2016, loss=0.787, v_nb=45]\n", "Epoch 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2522/2522 [00:12<00:00, 392.96batch/s, batch_nb=2016, loss=0.787, v_nb=45, val_mse=0.787]\n", "Epoch 2:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 2017/2522 [00:12<00:03, 160.61batch/s, batch_nb=2016, loss=0.469, v_nb=45, val_mse=0.787]\n", "Epoch 2:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 2066/2522 [00:12<00:02, 206.45batch/s, batch_nb=2016, loss=0.469, v_nb=45, val_mse=0.787]\n", "Epoch 2:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 2298/2522 [00:12<00:00, 284.06batch/s, batch_nb=2016, loss=0.469, v_nb=45, val_mse=0.787]\n", "Epoch 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2522/2522 [00:12<00:00, 384.70batch/s, batch_nb=2016, loss=0.469, v_nb=45, val_mse=0.782]\n", "Epoch 3:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 2017/2522 [00:12<00:03, 160.39batch/s, batch_nb=2016, loss=0.247, v_nb=45, val_mse=0.782]\n", "Epoch 3:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 2030/2522 [00:12<00:02, 183.97batch/s, batch_nb=2016, loss=0.247, v_nb=45, val_mse=0.782]\n", "Epoch 3:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 2269/2522 [00:12<00:00, 254.40batch/s, batch_nb=2016, loss=0.247, v_nb=45, val_mse=0.782]\n", "Epoch 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2522/2522 [00:12<00:00, 347.42batch/s, batch_nb=2016, loss=0.247, v_nb=45, val_mse=0.826]\n", "Epoch 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2522/2522 [00:12<00:00, 198.89batch/s, batch_nb=2016, loss=0.247, v_nb=45, val_mse=0.826]\n", "Testing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 631/631 [00:00<00:00, 2457.69batch/s]"]}, {"name": "stdout", "output_type": "stream", "text": ["{'progress_bar': {'test_mse': 0.7944674491882324}}\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n"]}], "source": ["from pytorch_lightning import Trainer\n", "\n", "model = LightningKorenMF(num_users,num_items,50)\n", "\n", "# most basic trainer, uses good defaults\n", "trainer = Trainer()    \n", "trainer.fit(model)\n", "trainer.test()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Still got time ?\n", "\n", "[Take a glance at the documentation](https://williamfalcon.github.io/pytorch-lightning/)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 2}